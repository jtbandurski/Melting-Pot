Running trails with the following arguments:  Namespace(num_workers=0, num_gpus=0, local=False, no_tune=False, algo='ppo', framework='torch', exp='pd_arena', seed=123, wandb_project='wdb_pr', wandb_group='wdb_gr', results_dir='./test_train_results', logging='DEBUG', downsample=True, as_test=False)
╭────────────────────────────────────────────────────────╮
│ Configuration for experiment     pd_arena              │
├────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator │
│ Scheduler                        FIFOScheduler         │
│ Number of trials                 1                     │
╰────────────────────────────────────────────────────────╯

View detailed results here: /home/jakub/master_thesis/Melting-Pot/test_train_results/torch/pd_arena
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/jakub/master_thesis/Melting-Pot/test_train_results/torch/pd_arena`

ResultGrid<[
  Result(
    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'agent_3': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.4282998754427982, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.045956997519048554, 'policy_loss': -0.043135849458093824, 'vf_loss': 0.08652313224828014, 'vf_explained_var': 0.19834418098131815, 'kl': 0.01284858615686844, 'entropy': 2.047551496212299, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_1': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.9862400957407096, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.049277059889685074, 'policy_loss': -0.0654992395056746, 'vf_loss': 0.01242186386938183, 'vf_explained_var': -1.0, 'kl': 0.01900157985436189, 'entropy': 2.0277761202592117, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_4': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3845743220442763, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.004672498002839394, 'policy_loss': -0.010191862017680436, 'vf_loss': 0.004560682685832636, 'vf_explained_var': -1.0, 'kl': 0.004793409650123182, 'entropy': 2.074529465650901, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_0': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 20.008121593181905, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.33695397886375966, 'policy_loss': 0.017890829115341872, 'vf_loss': 0.30815410397899073, 'vf_explained_var': 0.22147521208494136, 'kl': 0.05454522588467574, 'entropy': 2.043327783009945, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_5': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.2999039912835144, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.0045923547174495, 'policy_loss': -0.037930977411377124, 'vf_loss': 0.030487159204382736, 'vf_explained_var': -0.26402788758277895, 'kl': 0.0142573144878302, 'entropy': 2.0638509487494443, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_2': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.110117046955304, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.049695420495640394, 'policy_loss': -0.043461114426071826, 'vf_loss': 0.08863357825634571, 'vf_explained_var': -0.06284488408993452, 'kl': 0.02261477408857976, 'entropy': 2.0483327012795667, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_6': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.3719613882211537, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': 0.06199284120916556, 'policy_loss': -0.04794799808699351, 'vf_loss': 0.10540453783618525, 'vf_explained_var': 0.12268861685043726, 'kl': 0.02268150458360393, 'entropy': 1.994071011359875, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}, 'agent_7': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.721285611209579, 'cur_kl_coeff': 0.2, 'cur_lr': 5.000000000000001e-05, 'total_loss': -0.028936605303524397, 'policy_loss': -0.07951510223345115, 'vf_loss': 0.048563975145051966, 'vf_explained_var': -0.8445473379049546, 'kl': 0.010072613383044634, 'entropy': 2.0436870666650626, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 195.5, 'diff_num_grad_updates_vs_sampler_policy': 194.5}}, 'num_env_steps_sampled': 400, 'num_env_steps_trained': 400, 'num_agent_steps_sampled': 3200, 'num_agent_steps_trained': 3200}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3200, 'num_agent_steps_trained': 3200, 'num_env_steps_sampled': 400, 'num_env_steps_trained': 400, 'num_env_steps_sampled_this_iter': 400, 'num_env_steps_trained_this_iter': 400, 'num_env_steps_sampled_throughput_per_sec': 4.269974154836091, 'num_env_steps_trained_throughput_per_sec': 4.269974154836091, 'num_steps_trained_this_iter': 400, 'agent_timesteps_total': 3200, 'timers': {'training_iteration_time_ms': 93677.333, 'sample_time_ms': 18874.524, 'learn_time_ms': 74771.08, 'learn_throughput': 5.35, 'synch_weights_time_ms': 29.598}, 'counters': {'num_env_steps_sampled': 400, 'num_env_steps_trained': 400, 'num_agent_steps_sampled': 3200, 'num_agent_steps_trained': 3200}, 'done': True, 'trial_id': '44f7c_00000', 'perf': {'cpu_util_percent': 8.121641791044777, 'ram_util_percent': 65.20522388059703}, 'experiment_tag': '0'},
    path='/home/jakub/master_thesis/Melting-Pot/test_train_results/torch/pd_arena/PPO_meltingpot_44f7c_00000_0_2024-03-23_15-47-28',
    checkpoint=Checkpoint(local_path=/home/jakub/master_thesis/Melting-Pot/test_train_results/torch/pd_arena/PPO_meltingpot_44f7c_00000_0_2024-03-23_15-47-28/checkpoint_000001)
  )
]>
